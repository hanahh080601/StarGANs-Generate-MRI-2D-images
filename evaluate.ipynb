{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from model import Generator, ResUnetGenerator, ResUnet\n",
    "from dataset import CustomDataset\n",
    "import scipy\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10\n",
    "import pytorch_ssim.pytorch_ssim as pytorch_ssim\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"\n",
    "        Implement metrics for evaluating the results\n",
    "        - PSNR (Peak Signal-to-Noise Ratio)\n",
    "        - NMAE\n",
    "        - SSIM\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calculate_ssim(self, image1, image2):\n",
    "        image1, image2 = denorm(image1), denorm(image2)\n",
    "        ssim_value = pytorch_ssim.ssim(image1, image2)\n",
    "        return ssim_value\n",
    "\n",
    "    def calculate_psnr(self, image1, image2):\n",
    "        image1, image2 = denorm(image1), denorm(image2)\n",
    "        mse = np.mean(np.mean(np.array(image1) - np.array(image2)) ** 2)\n",
    "        if(mse == 0):  # MSE is zero means no noise is present in the signal. Therefore PSNR have no importance.\n",
    "            return 100\n",
    "        max_pixel = 1\n",
    "        psnr = 20 * log10(max_pixel / np.sqrt(mse))\n",
    "        return psnr\n",
    "    \n",
    "    def calculate_nmae(self, image1, image2):\n",
    "        image1, image2 = denorm(image1), denorm(image2)\n",
    "        # Flatten the 3D images to 1D arrays\n",
    "        flat_image1 = np.array(image1).flatten()\n",
    "        flat_image2 = np.array(image2).flatten()\n",
    "        \n",
    "        # Calculate the mean absolute error\n",
    "        abs_error = np.abs(flat_image1 - flat_image2)\n",
    "        mean_abs_error = np.mean(abs_error)\n",
    "        \n",
    "        # Calculate the range of the pixel values\n",
    "        pixel_range = np.max(flat_image1) - np.min(flat_image1)\n",
    "        \n",
    "        # Calculate the normalized mean absolute error\n",
    "        nmae = mean_abs_error / pixel_range\n",
    "        \n",
    "        return nmae\n",
    "    \n",
    "    def calculate_lpips(self, image1, image2):\n",
    "        lpips = LearnedPerceptualImagePatchSimilarity(net_type='vgg')\n",
    "        return lpips(image1, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(labels, dim):\n",
    "    \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
    "    batch_size = labels.size(0)\n",
    "    out = torch.zeros(batch_size, dim)\n",
    "    out[np.arange(batch_size), labels.long()] = 1\n",
    "    return out\n",
    "\n",
    "def create_labels(c_org, c_dim=4):\n",
    "    \"\"\"Generate target domain labels for debugging and testing.\"\"\"\n",
    "    c_trg_list = []\n",
    "    for i in range(c_dim):\n",
    "        c_trg = label2onehot(torch.ones(c_org.size(0))*i, c_dim)\n",
    "        c_trg_list.append(c_trg.to(CFG.device))\n",
    "    return c_trg_list\n",
    "\n",
    "def denorm(x):\n",
    "    \"\"\"Convert the range from [-1, 1] to [0, 1].\"\"\"\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    brats_data_dir = '/home/han/MRI_DATA/BraTS2020 StarGANs/image_2D/test'\n",
    "    ixi_data_dir = '/home/han/MRI_DATA/IXI StarGANs/image_2D/test'\n",
    "    # source_contrast = 't2' # pd, mra, t1, t2  # flair, t1ce, t1, t2\n",
    "    ixi_contrast_list = ['mra', 'pd', 't1', 't2']\n",
    "    brats_contrast_list = ['flair', 't1', 't1ce', 't2']\n",
    "    transform = []\n",
    "    transform.append(T.ToTensor())\n",
    "    transform.append(T.Resize((256, 256)))\n",
    "    transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "    transform = T.Compose(transform)\n",
    "    generator_dir = 'resunet_new_loss_both/models/200000-G.ckpt'\n",
    "    g_conv_dim = 64\n",
    "    c_dim = 4\n",
    "    repeat_num = 6\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device('cuda')\n",
    "    batch_size = 4\n",
    "    num_workers = 2\n",
    "    # device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = ResUnetGenerator(CFG.g_conv_dim, CFG.c_dim * 2 + 2, CFG.repeat_num)\n",
    "generator.load_state_dict(torch.load(CFG.generator_dir, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IXI:  ['mra', 'pd', 't1', 't2']\n",
      "IXI:  ['mra', 'pd', 't1', 't2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IXI:  ['mra', 'pd', 't1', 't2']\n",
      "IXI:  ['mra', 'pd', 't1', 't2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IXI:  ['mra', 'pd', 't1', 't2']\n",
      "IXI:  ['mra', 'pd', 't1', 't2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IXI:  ['mra', 'pd', 't1', 't2']\n",
      "IXI:  ['mra', 'pd', 't1', 't2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n",
      "BraTS2020:  ['flair', 't1', 't1ce', 't2']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "generator.to(CFG.device)\n",
    "metrics_scores = {}\n",
    "for contrast_list, data_dir in zip([CFG.ixi_contrast_list, CFG.brats_contrast_list], [CFG.ixi_data_dir, CFG.brats_data_dir]):\n",
    "    metrics_scores[data_dir.split('/')[4]] = {}\n",
    "    for source_contrast in contrast_list:\n",
    "        metrics_scores[data_dir.split('/')[4]][source_contrast] = {}\n",
    "        dataset = CustomDataset(data_dir, source_contrast, contrast_list, CFG.transform)\n",
    "        data_loader = DataLoader(dataset=dataset,\n",
    "                                  batch_size=CFG.batch_size,\n",
    "                                  shuffle=False,\n",
    "                                  num_workers=CFG.num_workers)\n",
    "        with torch.no_grad():\n",
    "            ssim = []\n",
    "            psnr = []\n",
    "            nmae = []\n",
    "            for i, data in enumerate(data_loader):\n",
    "                (x_real, c_org, path) = data['source']\n",
    "                x_real = x_real.to(CFG.device)\n",
    "                c_org = c_org.to(CFG.device)\n",
    "\n",
    "                # IXI\n",
    "                c_ixi_list = create_labels(c_org, CFG.c_dim)\n",
    "                zero_brats2020 = torch.zeros(x_real.size(0), CFG.c_dim).to(CFG.device)  \n",
    "                mask_ixi = label2onehot(torch.ones(x_real.size(0)), 2).to(CFG.device)\n",
    "\n",
    "                # BraTS\n",
    "                c_brats2020_list = create_labels(c_org, CFG.c_dim)\n",
    "                zero_ixi = torch.zeros(x_real.size(0), CFG.c_dim).to(CFG.device)             # Zero vector for XIX.\n",
    "                mask_brats2020 = label2onehot(torch.zeros(x_real.size(0)), 2).to(CFG.device)  # Mask vector: [1, 0].\n",
    "                \n",
    "                x_fake_list = []\n",
    "                target_list = []\n",
    "\n",
    "                if contrast_list == CFG.ixi_contrast_list:\n",
    "                    for j, c_fixed in enumerate(c_ixi_list):\n",
    "                        # c_trg = torch.cat([c_fixed, zero_ixi, mask_brats2020], dim=1)\n",
    "                        c_trg = torch.cat([zero_brats2020, c_fixed, mask_ixi], dim=1)\n",
    "                        x_fake = generator(x_real, c_trg)\n",
    "                        x_fake_list.append(x_fake)\n",
    "                    for j in contrast_list:\n",
    "                        target = data['target'][j][0]\n",
    "                        target_list.append(target)\n",
    "                    for j in range(len(contrast_list)):\n",
    "                        ssim_item = metrics.calculate_ssim(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        psnr_item = metrics.calculate_psnr(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        nmae_item = metrics.calculate_nmae(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        if contrast_list[j] not in metrics_scores[data_dir.split('/')[4]][source_contrast].keys():\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]] = {}\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'] = [ssim_item]\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'] = [psnr_item]\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'] = [nmae_item]\n",
    "                        else:\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'].append(ssim_item)\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'].append(psnr_item)\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'].append(nmae_item)\n",
    "                    if i%50 == 0:\n",
    "                        print('IXI: ', contrast_list)\n",
    "                        x_concat = torch.cat(x_fake_list, dim=3).data.cpu()\n",
    "                        x_concat = torch.cat([x_concat, torch.cat(target_list, dim=3).data.cpu()], dim=2)\n",
    "                        x_concat = (x_concat + 1) / 2\n",
    "                        x_concat = x_concat.clamp_(0, 1)\n",
    "                        save_image(x_concat, f\"{data_dir.split('/')[4]}/fake{i}.png\")\n",
    "\n",
    "                else:\n",
    "                    for j, c_fixed in enumerate(c_brats2020_list):\n",
    "                        c_trg = torch.cat([c_fixed, zero_ixi, mask_brats2020], dim=1)\n",
    "                        # c_trg = torch.cat([zero_brats2020, c_fixed, mask_ixi], dim=1)\n",
    "                        x_fake = generator(x_real, c_trg)\n",
    "                        x_fake_list.append(x_fake)\n",
    "                    for j in contrast_list:\n",
    "                        target = data['target'][j][0]\n",
    "                        target_list.append(target)\n",
    "                    for j in range(len(contrast_list)):\n",
    "                        ssim_item = metrics.calculate_ssim(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        psnr_item = metrics.calculate_psnr(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        nmae_item = metrics.calculate_nmae(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        if contrast_list[j] not in metrics_scores[data_dir.split('/')[4]][source_contrast].keys():\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]] = {}\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'] = [ssim_item]\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'] = [psnr_item]\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'] = [nmae_item]\n",
    "                        else:\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'].append(ssim_item)\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'].append(psnr_item)\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'].append(nmae_item)\n",
    "                    if i%100 == 0:\n",
    "                        print('BraTS2020: ', contrast_list)\n",
    "                        x_concat = torch.cat(x_fake_list, dim=3).data.cpu()\n",
    "                        x_concat = torch.cat([x_concat, torch.cat(target_list, dim=3).data.cpu()], dim=2)\n",
    "                        x_concat = (x_concat + 1) / 2\n",
    "                        x_concat = x_concat.clamp_(0, 1)\n",
    "                        save_image(x_concat, f\"{data_dir.split('/')[4]}/fake{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.069913305\n",
      "0.03236283\n",
      "0.029810015\n",
      "0.051985413\n",
      "0.059531458\n",
      "0.028398063\n",
      "0.061080262\n",
      "0.028997628\n",
      "0.031060133\n",
      "0.04598265\n",
      "0.04607626\n",
      "0.05112156\n"
     ]
    }
   ],
   "source": [
    "metrics = 'nmae'\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t2']['t1'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t2']['pd'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t2']['mra'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t1']['t2'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t1']['pd'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t1']['mra'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['pd']['t1'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['pd']['t2'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['pd']['mra'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['mra']['t1'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['mra']['t2'][metrics]))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['mra']['pd'][metrics]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(CFG.g_conv_dim, CFG.c_dim, CFG.repeat_num)\n",
    "generator.load_state_dict(torch.load(CFG.generator_dir, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "generator.to(CFG.device)\n",
    "metrics_scores = {}\n",
    "for contrast_list, data_dir in zip([CFG.ixi_contrast_list, CFG.brats_contrast_list], [CFG.ixi_data_dir, CFG.brats_data_dir]):\n",
    "    if data_dir.split('/')[4] == 'BraTS2020 StarGANs':\n",
    "        metrics_scores[data_dir.split('/')[4]] = {}\n",
    "        for source_contrast in contrast_list:\n",
    "            metrics_scores[data_dir.split('/')[4]][source_contrast] = {}\n",
    "            dataset = CustomDataset(data_dir, source_contrast, contrast_list, CFG.transform)\n",
    "            data_loader = DataLoader(dataset=dataset,\n",
    "                                    batch_size=CFG.batch_size,\n",
    "                                    shuffle=False,\n",
    "                                    num_workers=CFG.num_workers)\n",
    "            with torch.no_grad():\n",
    "                ssim = []\n",
    "                psnr = []\n",
    "                nmae = []\n",
    "                for i, data in enumerate(data_loader):\n",
    "                    (x_real, c_org, path) = data['source']\n",
    "                    x_real = x_real.to(CFG.device)\n",
    "                    c_trg_list = create_labels(c_org, CFG.c_dim)\n",
    "                    \n",
    "                    x_fake_list = []\n",
    "                    target_list = []\n",
    "\n",
    "                    for c_trg in c_trg_list:\n",
    "                        x_fake_list.append(generator(x_real, c_trg))\n",
    "                    for j in contrast_list:\n",
    "                        target = data['target'][j][0].data.cpu()\n",
    "                        target_list.append(target)\n",
    "                    for j in range(len(contrast_list)):\n",
    "                        ssim_item = metrics.calculate_ssim(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        psnr_item = metrics.calculate_psnr(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        nmae_item = metrics.calculate_nmae(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                        if contrast_list[j] not in metrics_scores[data_dir.split('/')[4]][source_contrast].keys():\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]] = {}\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'] = [ssim_item]\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'] = [psnr_item]\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'] = [nmae_item]\n",
    "                        else:\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'].append(ssim_item)\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'].append(psnr_item)\n",
    "                            metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'].append(nmae_item)\n",
    "                    # if i%50 == 0:\n",
    "                    #     x_concat = torch.cat(x_fake_list, dim=3).data.cpu()\n",
    "                    #     x_concat = torch.cat([x_concat, torch.cat(target_list, dim=3).data.cpu()], dim=2)\n",
    "                    #     x_concat = (x_concat + 1) / 2\n",
    "                    #     x_concat = x_concat.clamp_(0, 1)\n",
    "                    #     save_image(denorm(x_concat.data.cpu()), f\"{data_dir.split('/')[4]}/single_fake{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03876209\n",
      "0.041596036\n",
      "0.034268912\n",
      "0.043283213\n",
      "0.035996106\n",
      "0.04559305\n",
      "0.042630948\n",
      "0.04008158\n",
      "0.056440245\n",
      "0.045357995\n",
      "0.038583476\n",
      "0.048108928\n"
     ]
    }
   ],
   "source": [
    "metrics = 'nmae'\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t2']['t1']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t2']['pd']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t2']['mra']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t1']['t2']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t1']['pd']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['t1']['mra']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['pd']['t1']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['pd']['t2']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['pd']['mra']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['mra']['t1']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['mra']['t2']['ssim']))\n",
    "print(np.mean(metrics_scores['IXI StarGANs']['mra']['pd']['ssim']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.generator_dir = 'stargan_ixi/models/200000-G.ckpt'\n",
    "generator = Generator(CFG.g_conv_dim, CFG.c_dim, CFG.repeat_num)\n",
    "generator = Generator(CFG.g_conv_dim, CFG.c_dim*2+2, CFG.repeat_num)\n",
    "generator.load_state_dict(torch.load(CFG.generator_dir, map_location=lambda storage, loc: storage))\n",
    "data_dir = CFG.ixi_data_dir\n",
    "contrast_list = CFG.ixi_contrast_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_contrast in contrast_list:\n",
    "    metrics_scores[data_dir.split('/')[4]][source_contrast] = {}\n",
    "    dataset = CustomDataset(data_dir, source_contrast, contrast_list, CFG.transform)\n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "                            batch_size=CFG.batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=CFG.num_workers)\n",
    "    with torch.no_grad():\n",
    "        ssim = []\n",
    "        psnr = []\n",
    "        nmae = []\n",
    "        for i, data in enumerate(data_loader):\n",
    "            (x_real, c_org, path) = data['source']\n",
    "            x_real = x_real.to(CFG.device)\n",
    "            c_trg_list = create_labels(c_org, CFG.c_dim)\n",
    "            \n",
    "            x_fake_list = [x_real]\n",
    "            target_list = [x_real]\n",
    "\n",
    "            for c_trg in c_trg_list:\n",
    "                x_fake_list.append(generator(x_real, c_trg))\n",
    "            for j in contrast_list:\n",
    "                target = data['target'][j][0].data.cpu()\n",
    "                target_list.append(target)\n",
    "            for j in range(len(contrast_list)):\n",
    "                ssim_item = metrics.calculate_ssim(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                psnr_item = metrics.calculate_psnr(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                nmae_item = metrics.calculate_nmae(target_list[j].data.cpu(), x_fake_list[j].data.cpu())\n",
    "                if contrast_list[j] not in metrics_scores[data_dir.split('/')[4]][source_contrast].keys():\n",
    "                    metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]] = {}\n",
    "                    metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'] = [ssim_item]\n",
    "                    metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'] = [psnr_item]\n",
    "                    metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'] = [nmae_item]\n",
    "                else:\n",
    "                    metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['ssim'].append(ssim_item)\n",
    "                    metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['psnr'].append(psnr_item)\n",
    "                    metrics_scores[data_dir.split('/')[4]][source_contrast][contrast_list[j]]['nmae'].append(nmae_item)\n",
    "            if i%50 == 0:\n",
    "                x_concat = torch.cat(x_fake_list, dim=3).data.cpu()\n",
    "                x_concat = torch.cat([x_concat, torch.cat(target_list, dim=3).data.cpu()], dim=2)\n",
    "                x_concat = (x_concat + 1) / 2\n",
    "                x_concat = x_concat.clamp_(0, 1)\n",
    "                save_image(denorm(x_concat.data.cpu()), f\"{data_dir.split('/')[4]}/single_qualitative_fake{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f76ae0342d0d8e138d7b9f01e688e783adfb67c5401e5fbe0947b36ee06d4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
