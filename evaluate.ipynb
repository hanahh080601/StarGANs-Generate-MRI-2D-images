{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "from model import Generator, ResUnetGenerator\n",
    "from dataset import CustomDataset\n",
    "import scipy\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10\n",
    "import pytorch_ssim.pytorch_ssim as pytorch_ssim\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \"\"\"\n",
    "        Implement metrics for evaluating the results\n",
    "        - PSNR (Peak Signal-to-Noise Ratio)\n",
    "        - NMAE\n",
    "        - SSIM\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calculate_ssim(self, image1, image2):\n",
    "        image1, image2 = denorm(image1), denorm(image2)\n",
    "        ssim_value = pytorch_ssim.ssim(image1, image2)\n",
    "        return ssim_value\n",
    "\n",
    "    def calculate_psnr(self, image1, image2):\n",
    "        image1, image2 = denorm(image1), denorm(image2)\n",
    "        mse = np.mean(np.mean(np.array(image1) - np.array(image2)) ** 2)\n",
    "        if(mse == 0):  # MSE is zero means no noise is present in the signal. Therefore PSNR have no importance.\n",
    "            return 100\n",
    "        max_pixel = 1\n",
    "        psnr = 20 * log10(max_pixel / np.sqrt(mse))\n",
    "        return psnr\n",
    "    \n",
    "    def calculate_nmae(self, image1, image2):\n",
    "        image1, image2 = denorm(image1), denorm(image2)\n",
    "        # Flatten the 3D images to 1D arrays\n",
    "        flat_image1 = np.array(image1).flatten()\n",
    "        flat_image2 = np.array(image2).flatten()\n",
    "        \n",
    "        # Calculate the mean absolute error\n",
    "        abs_error = np.abs(flat_image1 - flat_image2)\n",
    "        mean_abs_error = np.mean(abs_error)\n",
    "        \n",
    "        # Calculate the range of the pixel values\n",
    "        pixel_range = np.max(flat_image1) - np.min(flat_image1)\n",
    "        \n",
    "        # Calculate the normalized mean absolute error\n",
    "        nmae = mean_abs_error / pixel_range\n",
    "        \n",
    "        return nmae\n",
    "    \n",
    "    def calculate_lpips(self, image1, image2):\n",
    "        lpips = LearnedPerceptualImagePatchSimilarity(net_type='vgg')\n",
    "        return lpips(image1, image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_dir = '/home/han/MRI_DATA/BraTS2020 StarGANs/image_2D/test'\n",
    "    source_contrast = 't2' # pd, mra, t1, t2  # flair, t1ce, t1, t2\n",
    "    # contrast_list = ['mra', 'pd', 't1', 't2']\n",
    "    contrast_list = ['flair', 't1ce', 't1', 't2']\n",
    "    transform = []\n",
    "    transform.append(T.ToTensor())\n",
    "    transform.append(T.Resize(256))\n",
    "    transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "    transform = T.Compose(transform)\n",
    "    generator_dir = 'stargan_both/models/200000-G.ckpt'\n",
    "    g_conv_dim = 64\n",
    "    c_dim = 4\n",
    "    repeat_num = 6\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2onehot(labels, dim):\n",
    "    \"\"\"Convert label indices to one-hot vectors.\"\"\"\n",
    "    batch_size = labels.size(0)\n",
    "    out = torch.zeros(batch_size, dim)\n",
    "    out[np.arange(batch_size), labels.long()] = 1\n",
    "    return out\n",
    "\n",
    "def create_labels(c_org, c_dim=4):\n",
    "    \"\"\"Generate target domain labels for debugging and testing.\"\"\"\n",
    "    c_trg_list = []\n",
    "    for i in range(c_dim):\n",
    "        c_trg = label2onehot(torch.ones(c_org.size(0))*i, c_dim)\n",
    "        c_trg_list.append(c_trg.to(CFG.device))\n",
    "    return c_trg_list\n",
    "\n",
    "def denorm(x):\n",
    "    \"\"\"Convert the range from [-1, 1] to [0, 1].\"\"\"\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp_(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(CFG.data_dir, CFG.source_contrast, CFG.contrast_list, CFG.transform)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=1, shuffle=True, num_workers=1)\n",
    "metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(CFG.g_conv_dim, CFG.c_dim * 2 + 2, CFG.repeat_num)\n",
    "generator.load_state_dict(torch.load(CFG.generator_dir, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSIM:  0.8269338\n",
      "PSNR:  30.4808867340839\n",
      "NMAE:  0.06497672\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "generator.to(CFG.device)\n",
    "with torch.no_grad():\n",
    "    ssim = []\n",
    "    psnr = []\n",
    "    nmae = []\n",
    "    for i, data in enumerate(data_loader):\n",
    "        (x_real, c_org, path) = data['source']\n",
    "        x_real = x_real.to(CFG.device)\n",
    "        c_org = c_org.to(CFG.device)\n",
    "\n",
    "        # HERE\n",
    "        # c_ixi_list = create_labels(c_org, CFG.c_dim)\n",
    "        # zero_brats2020 = torch.zeros(x_real.size(0), CFG.c_dim).to(CFG.device)  \n",
    "        # mask_ixi = label2onehot(torch.ones(x_real.size(0)), 2).to(CFG.device)\n",
    "        c_brats2020_list = create_labels(c_org, CFG.c_dim)\n",
    "        zero_ixi = torch.zeros(x_real.size(0), CFG.c_dim).to(CFG.device)             # Zero vector for XIX.\n",
    "        mask_brats2020 = label2onehot(torch.zeros(x_real.size(0)), 2).to(CFG.device)  # Mask vector: [1, 0].\n",
    "\n",
    "        \n",
    "        x_fake_list = []\n",
    "        target_list = []\n",
    "        for j, c_fixed in enumerate(c_brats2020_list):\n",
    "            c_trg = torch.cat([c_fixed, zero_ixi, mask_brats2020], dim=1)\n",
    "            # c_trg = torch.cat([zero_brats2020, c_fixed, mask_ixi], dim=1)\n",
    "            x_fake = generator(x_real, c_trg)\n",
    "            x_fake_list.append(x_fake)\n",
    "        for j in CFG.contrast_list:\n",
    "            target = data['target'][j][0]\n",
    "            target_list.append(target)\n",
    "        for j in range(len(CFG.contrast_list)):\n",
    "            ssim.append(metrics.calculate_ssim(target_list[j], x_fake_list[j]))\n",
    "            psnr.append(metrics.calculate_psnr(target_list[j], x_fake_list[j]))\n",
    "            nmae.append(metrics.calculate_nmae(target_list[j], x_fake_list[j]))\n",
    "\n",
    "        x_concat = torch.cat(x_fake_list, dim=3).data.cpu()\n",
    "        x_concat = torch.cat([x_concat, torch.cat(target_list, dim=3).data.cpu()], dim=2)\n",
    "        x_concat = (x_concat + 1) / 2\n",
    "        x_concat = x_concat.clamp_(0, 1)\n",
    "        save_image(x_concat, f'eval_ixi_stargan/fake{i}.png')\n",
    "    print(\"SSIM: \", np.array(ssim).mean())\n",
    "    print(\"PSNR: \", np.array(psnr).mean())\n",
    "    print(\"NMAE: \", np.array(nmae).mean())\n",
    "\n",
    "# StarGAN\n",
    "# IXI source MRA\n",
    "# SSIM:  0.75208205\n",
    "# PSNR:  38.86268557462074\n",
    "# NMAE:  0.037938464\n",
    "\n",
    "# IXI source = PD\n",
    "# SSIM:  0.80015516\n",
    "# PSNR:  39.29677431441381\n",
    "# NMAE:  0.03180834\n",
    "\n",
    "# IXI source = T1\n",
    "# SSIM:  0.7346829\n",
    "# PSNR:  39.814971066299115\n",
    "# NMAE:  0.038296565\n",
    "\n",
    "# IXI source = T2\n",
    "# SSIM:  0.799478\n",
    "# PSNR:  40.696188551363484\n",
    "# NMAE:  0.031956453\n",
    "\n",
    "# BraTS2020 source = FLAIR\n",
    "# SSIM:  0.84171426\n",
    "# PSNR:  33.61483340884243\n",
    "# NMAE:  0.058331743\n",
    "\n",
    "# BraTS2020 source = T1CE\n",
    "# SSIM:  0.8246284\n",
    "# PSNR:  28.547625551237427\n",
    "# NMAE:  0.06697038\n",
    "\n",
    "# BraTS2020 source = T1\n",
    "# SSIM:  0.8344398\n",
    "# PSNR:  26.675615710097293\n",
    "# NMAE:  0.0704227\n",
    "\n",
    "# BraTS2020 source = T2\n",
    "# SSIM:  0.8269338\n",
    "# PSNR:  30.4808867340839\n",
    "# NMAE:  0.06497672\n",
    "\n",
    "# ResUnet\n",
    "# IXI source = MRA\n",
    "# SSIM:  0.73379254\n",
    "# PSNR:  40.97990127919558\n",
    "# NMAE:  0.034802567\n",
    "\n",
    "# IXI source = PD\n",
    "# SSIM:  0.77352405\n",
    "# PSNR:  41.696309792660564\n",
    "# NMAE:  0.030027147\n",
    "\n",
    "# IXI source = T1\n",
    "# SSIM:  0.7168928\n",
    "# PSNR:  41.60366481777639\n",
    "# NMAE:  0.034858994\n",
    "\n",
    "# IXI source = T2\n",
    "# SSIM:  0.7844148\n",
    "# PSNR:  39.04168398485751\n",
    "# NMAE:  0.031735655\n",
    "\n",
    "# BraTS2020 source = FLAIR\n",
    "# SSIM:  0.79582345\n",
    "# PSNR:  32.78408054369021\n",
    "# NMAE:  0.057049632\n",
    "\n",
    "# BraTS2020 source = T1CE\n",
    "# SSIM:  0.7823191\n",
    "# PSNR:  29.32913845714312\n",
    "# NMAE:  0.06274834\n",
    "\n",
    "# BraTS2020 source = T1\n",
    "# SSIM:  0.7845728\n",
    "# PSNR:  28.776334321491472\n",
    "# NMAE:  0.06536168\n",
    "\n",
    "# BraTS2020 source = T2\n",
    "# SSIM:  0.77713275\n",
    "# PSNR:  30.846138165699482\n",
    "# NMAE:  0.064423576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "_ = torch.manual_seed(123)\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
    "lpips = LearnedPerceptualImagePatchSimilarity(net_type='vgg')\n",
    "# LPIPS needs the images to be in the [-1, 1] range.\n",
    "img1 = (torch.rand(10, 3, 100, 100) * 2) - 1\n",
    "img2 = (torch.rand(10, 3, 100, 100) * 2) - 1\n",
    "loss = lpips(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.3493258, dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = loss.detach().numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-25 00:05:42.508979: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-25 00:05:42.541377: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 00:05:42.974711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-25 00:05:43.455689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-25 00:05:43.475630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-25 00:05:43.475908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "\n",
      "***** TensorBoard Uploader *****\n",
      "\n",
      "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
      "the following directory:\n",
      "\n",
      "/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/stargan_both/logs\n",
      "\n",
      "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
      "data.\n",
      "\n",
      "Your use of this service is subject to Google's Terms of Service\n",
      "<https://policies.google.com/terms> and Privacy Policy\n",
      "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
      "<https://tensorboard.dev/policy/terms/>.\n",
      "\n",
      "This notice will not be shown again while you are logged into the uploader.\n",
      "To log out, run `tensorboard dev auth revoke`.\n",
      "\n",
      "Continue? (yes/NO) ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/bin/tensorboard\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/tensorboard/main.py\", line 46, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/tensorboard/program.py\", line 276, in main\n",
      "    return runner(self.flags) or 0\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 691, in run\n",
      "    return _run(flags, self._experiment_url_callback)\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 93, in _run\n",
      "    _prompt_for_user_ack(intent)\n",
      "  File \"/home/han/Desktop/hanlhn_dut/StarGANs-Generate-MRI-2D-images/venv/lib/python3.8/site-packages/tensorboard/uploader/uploader_subcommand.py\", line 66, in _prompt_for_user_ack\n",
      "    response = input(\"Continue? (yes/NO) \")\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard dev upload --logdir resunet_both/logs \\\n",
    "    --name \"(optional) My latest experiment\" \\\n",
    "    --description \"(optional) Simple comparison of several hyperparameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2f76ae0342d0d8e138d7b9f01e688e783adfb67c5401e5fbe0947b36ee06d4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
